{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import importlib\n",
    "import utils.minimization as minim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Reloading modules\n",
    "importlib.reload(minim)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bbb513092b3bed31"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x = pd.read_csv('parkinsons_updrs.csv')\n",
    "features = x.columns  # first columns will contain the names of the features\n",
    "print(f'Dataset size = {x.shape}')\n",
    "print(f'Dataset features count = {len(features)}')\n",
    "# print(features)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a27bf1dd73ae3e05"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Features list:\n",
    "- subject#: patient number\n",
    "- age: age of the patient\n",
    "- sex: sex of the patient\n",
    "- test_time: period from the beginning of the measurement (integer -> day, float -> hour from 0AM to 12PM)\n",
    "- motor_UPDRS:\n",
    "- total_UPDRS:\n",
    "Jitter, in general, is the variation of the fundamental frequency in signals that should be periodic but are not\n",
    "- Jitter(%), Jitter(Abs), Jitter:RAP, Jitter:PPQ5, Jitter:DDP\n",
    "Shimmer, in general, is the variation of amplitude in signals that should be periodic but are not\n",
    "- Shimmer, Shimmer(dB), Shimmer:APQ3, Shimmer:APQ5, Shipper:APQ11, Shimmer:DDA\n",
    "- NHR: Noise to Harmonics Ratio\n",
    "- HNR: Harmonic to Noise Ratio\n",
    "- RPDE: Recurrence Period Density Entropy\n",
    "- DFA: Detrended Fluctuation Analysis\n",
    "- PPE: Perceived Vocal Effort is the measure of effort (physical and cognitive) used to produce speech"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1cbc8b1104745737"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# print(pd.unique(x['subject#']))\n",
    "# x.plot.scatter('subject#', 'age')\n",
    "x.loc[:, ~x.columns.isin(['subject#', 'sex'])].plot.hist(\n",
    "    bins=50)  # 'subject#' and 'sex' are removed to have a clearer histogram\n",
    "# bins is the number of rectangles, so the lesser -> the more values will be represented with a single rectangle"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c5d4f5799aa4c531"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = pd.DataFrame()\n",
    "subj = np.unique(x['subject#'])\n",
    "for k in subj:  # for each subject#\n",
    "    xk = x[x['subject#'] == k]\n",
    "    xk1 = xk.copy()\n",
    "    xk1.test_time = xk1.test_time.astype(int)\n",
    "    xk1['g'] = xk1['test_time']  # new property called 'g' containing the 'test_time' property\n",
    "    # now the dataframe collapses using 'g' as pivot, and computing the mean for each other property\n",
    "    v = xk1.groupby('g').mean()\n",
    "    X = pd.concat([X, v], axis=0, ignore_index=True)  # axis=0 -> concatenation along rows. (0, 1) -> (rows, columns)\n",
    "features = x.columns\n",
    "Np, Nc = X.shape\n",
    "print(f'X shape = {X.shape}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2d65bdcb9b79d0d0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Xnorm = (X - X.mean()) / X.std()\n",
    "c = Xnorm.cov()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c38a03f2e379740b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.matshow(np.abs(c.values), fignum=0)\n",
    "plt.xticks(np.arange(len(features)), features, rotation=90)\n",
    "plt.yticks(np.arange(len(features)), features, rotation=0)\n",
    "plt.colorbar()\n",
    "plt.title('just the title')\n",
    "plt.tight_layout()\n",
    "plt.savefig('./corr_coeff.png')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cbb4ff5d1b88bf6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "c.total_UPDRS.plot()\n",
    "plt.grid()\n",
    "plt.xticks(np.arange(len(features)), features, rotation=90)\n",
    "plt.axhline(y=0, color='g')\n",
    "plt.title('Correlation coefficients of total_UPDRS versus other features')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "39a6f28aa44179ca"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "seed = 319244\n",
    "Xsh = X.sample(frac=1, replace=False, random_state=seed, axis=0, ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a15f3067bfa431f0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Percentages\n",
    "percent_training = 0.5\n",
    "percent_test = 0.25\n",
    "percent_validation = 1 - percent_training - percent_test"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1ae1d94ffca11529"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Ntr = int(Np * percent_training)  # Number of training points\n",
    "Nte = int(Np * percent_test)  # Number of test points\n",
    "Nva = Np - Ntr - Nte\n",
    "\n",
    "X_tr = Xsh[:Ntr]\n",
    "\n",
    "mm = X_tr.mean()\n",
    "ss = X_tr.std()\n",
    "my = mm['total_UPDRS']\n",
    "sy = ss['total_UPDRS']\n",
    "mm_vals = mm.values\n",
    "ss_vals = ss.values"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c86ef7ebc1626af1"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "Xsh_norm = (Xsh - mm_vals) / ss_vals  # normalization of all parameters\n",
    "ysh_norm = Xsh_norm['total_UPDRS']  # total_UPDRS will be the regressand\n",
    "# Xsh_norm = Xsh_norm[['motor_UPDRS', 'age', 'PPE']]  # keeping only these three regressors\n",
    "Xsh_norm = Xsh_norm.drop(['total_UPDRS', 'subject#', 'test_time'], axis=1)  # removing the regressand and other useless\n",
    "# or known correlated features\n",
    "\n",
    "X_tr_norm = Xsh_norm[:Ntr].values\n",
    "X_va_norm = Xsh_norm[Ntr:Ntr + Nva].values\n",
    "X_te_norm = Xsh_norm[-Nte:].values\n",
    "y_tr_norm = ysh_norm[:Ntr].values\n",
    "y_va_norm = ysh_norm[Ntr:Ntr + Nva].values\n",
    "y_te_norm = ysh_norm[-Nte:].values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T20:35:53.604774500Z",
     "start_time": "2023-11-17T20:35:53.588885300Z"
    }
   },
   "id": "966f6ac10ac17cef"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "# Useful functions\n",
    "def eucl_distance(v1, v2):\n",
    "    assert len(v1) == len(v2)\n",
    "    v_diff = v1 - v2\n",
    "    return pow(v_diff.T @ v_diff, 0.5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T20:35:54.106991200Z",
     "start_time": "2023-11-17T20:35:54.103970600Z"
    }
   },
   "id": "37a4c1312ab173d3"
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "# Solver control plane\n",
    "r2 = 100\n",
    "t = 1\n",
    "s2 = 0.001\n",
    "N = 10"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T20:35:54.432257200Z",
     "start_time": "2023-11-17T20:35:54.427710400Z"
    }
   },
   "id": "10bad3fea89b3625"
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "for row in range(Nva):\n",
    "    x = X_va_norm[row]\n",
    "    distances = [eucl_distance(x, X_tr_norm[i]) for i in range(Ntr)]\n",
    "    i_order = np.argsort(distances)\n",
    "    closer_X = np.array([X_tr_norm[i] for i in i_order[:N - 1]])\n",
    "    closer_y = np.array([y_tr_norm[i] for i in i_order[:N - 1]])\n",
    "    Xr = np.concatenate((closer_X, [x]), axis=0)\n",
    "    Rn = np.empty(shape=(N, N))\n",
    "    for n in range(N):\n",
    "        for k in range(N):\n",
    "            Rn[n, k] = t * np.exp(- (np.linalg.norm(Xr[n] - Xr[k]) ** 2) / (2 * r2))\n",
    "            if n == k:\n",
    "                Rn[n, k] = Rn[n, k] + s2 ** 2\n",
    "    k = Rn[-1, :N - 1]\n",
    "    d = Rn[-1, -1]\n",
    "    Rn_sub_inv = np.linalg.inv(Rn[:N - 1, :N - 1])\n",
    "    y_hat = k.T @ Rn_sub_inv @ closer_y\n",
    "    variance = d - k.T @ Rn_sub_inv @ k"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T20:42:24.672374700Z",
     "start_time": "2023-11-17T20:42:24.255768400Z"
    }
   },
   "id": "c1ee1a2a0e1fbb08"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# to plot and see a covariance matrix\n",
    "plt.figure()\n",
    "plt.matshow(np.abs(Rn), fignum=0)\n",
    "plt.colorbar()\n",
    "plt.title('$R_N$ covariance matrix')\n",
    "plt.tight_layout()\n",
    "# plt.savefig('./corr_coeff.png')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "62dfcbc96401dcad"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# De-normalization, to make data readable by a medical doctor\n",
    "y_hat_tr = y_hat_tr_norm * sy + my\n",
    "y_tr = y_tr_norm * sy + my\n",
    "y_hat_te = y_hat_te_norm * sy + my\n",
    "y_te = y_te_norm * sy + my"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff8e99742e9489b0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "E_tr = y_tr - y_hat_tr\n",
    "E_te = y_te - y_hat_te\n",
    "e = [E_tr, E_te]\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.hist(e, bins=40, density=True, histtype='bar')\n",
    "label = ['Training', 'Test']\n",
    "plt.xlabel(r'$e=y-\\^y$')\n",
    "plt.ylabel(r'$P(e$ in bin$)$')\n",
    "plt.legend(label)\n",
    "plt.ylim([0, 0.21])\n",
    "plt.xlim([-11, 45])\n",
    "plt.grid()\n",
    "plt.title('LLS - Error histograms')\n",
    "plt.tight_layout()\n",
    "plt.savefig('./LLS-Error-hist.png')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fb3b247c49a27d12"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The last plot shows that the error pdf is like a mixture of two gaussian pdfs.\n",
    "The fact that the two pdfs of training and test looks very similar is because there's no overfitting. If overfitting\n",
    "was present, the error in the training would have been more concentrated on the 0 value, while the pdf of the test\n",
    "would have depended on the similarity of the two datasets: if similar, the two pdfs could have been similar, otherwise\n",
    "the test one would have quite even distributed values, in height, from the regression line, enlighting a randomness on the performance in guessing the new values. (Discuss this)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bf73b3f172acd7b2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_hat_te = (X_te_norm @ w_hat) * sy + my\n",
    "y_te = y_te_norm * sy + my\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(y_te, y_hat_te, '.')\n",
    "v = plt.axis()\n",
    "plt.plot([v[0], v[1]], [v[0], v[1]], 'r', linewidth=2)\n",
    "plt.xlabel(r'$y$')\n",
    "plt.ylabel(r'$\\^y$')\n",
    "plt.grid()\n",
    "plt.title('LLS - Test')\n",
    "plt.tight_layout()\n",
    "plt.savefig('./LLS-yhat_vs_y.png')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c20bf239ae2b2347"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The estimation is quite reliable, except for some cases that stay near 7-8 UPDRS points far from the\n",
    "original value. This justifies the second gaussian with its average near 7-8. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f50f21541706f9ef"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "E_tr_min = E_tr.min()\n",
    "E_tr_max = E_tr.max()\n",
    "E_tr_mu = E_tr.mean()\n",
    "E_tr_sig = E_tr.std()\n",
    "E_tr_MSE = np.mean(E_tr ** 2)\n",
    "R2_tr = 1 - E_tr_MSE / np.var(y_tr)\n",
    "c_tr = np.mean((y_tr - y_tr.mean()) * (y_hat_tr - y_hat_tr.mean())) / (y_tr.std() * y_hat_tr.std())\n",
    "E_te_min = E_te.min()\n",
    "E_te_max = E_te.max()\n",
    "E_te_mu = E_te.mean()\n",
    "E_te_sig = E_te.std()\n",
    "E_te_MSE = np.mean(E_te ** 2)\n",
    "R2_te = 1 - E_te_MSE / np.var(y_te)\n",
    "c_te = np.mean((y_te - y_te.mean()) * (y_hat_te - y_hat_te.mean())) / (y_te.std() * y_hat_te.std())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6e6b8a28cc6befce"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rows = ['Training', 'Test']\n",
    "cols = ['min', 'max', 'mean', 'std', 'MSE', 'R^2', 'correlation coefficient']\n",
    "p = np.array([\n",
    "    [E_tr_min, E_tr_max, E_tr_mu, E_tr_sig, E_tr_MSE, R2_tr, c_tr],\n",
    "    [E_te_min, E_te_max, E_te_mu, E_te_sig, E_te_MSE, R2_te, c_te]\n",
    "])\n",
    "results = pd.DataFrame(p, columns=cols, index=rows)\n",
    "print(results)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6dbbd8b6daa3237"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Comments on these results:\n",
    "The test dataset has one outlier, so it shows a relative high error.\n",
    "The mean is close to zero for the training set (which is expected), while it is a bit higher for the test set because the mean of total_UPDRS is calculated on the train set, so since values are different it is a normal and possible scenario.\n",
    "The $R^2$ (coefficient of determination, the \"score of prediction\") is 0.92, which is a good result for the regression."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c60cc1cc1c9e6ed"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "840c258e4273c9ab"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
