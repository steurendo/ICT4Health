{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import importlib\n",
    "import utils.minimization as minim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Reloading modules\n",
    "importlib.reload(minim)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bbb513092b3bed31"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x = pd.read_csv('parkinsons_updrs.csv')\n",
    "features = x.columns  # first columns will contain the names of the features\n",
    "print(f'Dataset size = {x.shape}')\n",
    "print(f'Dataset features count = {len(features)}')\n",
    "# print(features)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a27bf1dd73ae3e05"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Features list:\n",
    "- subject#: patient number\n",
    "- age: age of the patient\n",
    "- sex: sex of the patient\n",
    "- test_time: period from the beginning of the measurement (integer -> day, float -> hour from 0AM to 12PM)\n",
    "- motor_UPDRS:\n",
    "- total_UPDRS:\n",
    "Jitter, in general, is the variation of the fundamental frequency in signals that should be periodic but are not\n",
    "- Jitter(%), Jitter(Abs), Jitter:RAP, Jitter:PPQ5, Jitter:DDP\n",
    "Shimmer, in general, is the variation of amplitude in signals that should be periodic but are not\n",
    "- Shimmer, Shimmer(dB), Shimmer:APQ3, Shimmer:APQ5, Shipper:APQ11, Shimmer:DDA\n",
    "- NHR: Noise to Harmonics Ratio\n",
    "- HNR: Harmonic to Noise Ratio\n",
    "- RPDE: Recurrence Period Density Entropy\n",
    "- DFA: Detrended Fluctuation Analysis\n",
    "- PPE: Perceived Vocal Effort is the measure of effort (physical and cognitive) used to produce speech"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1cbc8b1104745737"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# print(pd.unique(x['subject#']))\n",
    "# x.plot.scatter('subject#', 'age')\n",
    "x.loc[:, ~x.columns.isin(['subject#', 'sex'])].plot.hist(\n",
    "    bins=50)  # 'subject#' and 'sex' are removed to have a clearer histogram\n",
    "# bins is the number of rectangles, so the lesser -> the more values will be represented with a single rectangle"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c5d4f5799aa4c531"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = pd.DataFrame()\n",
    "subj = np.unique(x['subject#'])\n",
    "for k in subj:  # for each subject#\n",
    "    xk = x[x['subject#'] == k]\n",
    "    xk1 = xk.copy()\n",
    "    xk1.test_time = xk1.test_time.astype(int)\n",
    "    xk1['g'] = xk1['test_time']  # new property called 'g' containing the 'test_time' property\n",
    "    # now the dataframe collapses using 'g' as pivot, and computing the mean for each other property\n",
    "    v = xk1.groupby('g').mean()\n",
    "    X = pd.concat([X, v], axis=0, ignore_index=True)  # axis=0 -> concatenation along rows. (0, 1) -> (rows, columns)\n",
    "features = x.columns\n",
    "Np, Nc = X.shape\n",
    "print(f'X shape = {X.shape}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2d65bdcb9b79d0d0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Xnorm = (X - X.mean()) / X.std()\n",
    "c = Xnorm.cov()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c38a03f2e379740b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.matshow(np.abs(c.values), fignum=0)\n",
    "plt.xticks(np.arange(len(features)), features, rotation=90)\n",
    "plt.yticks(np.arange(len(features)), features, rotation=0)\n",
    "plt.colorbar()\n",
    "plt.title('just the title')\n",
    "plt.tight_layout()\n",
    "plt.savefig('./corr_coeff.png')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cbb4ff5d1b88bf6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "c.total_UPDRS.plot()\n",
    "plt.grid()\n",
    "plt.xticks(np.arange(len(features)), features, rotation=90)\n",
    "plt.axhline(y=0, color='g')\n",
    "plt.title('Correlation coefficients of total_UPDRS versus other features')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "39a6f28aa44179ca"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "seed = 319244\n",
    "Xsh = X.sample(frac=1, replace=False, random_state=seed, axis=0, ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a15f3067bfa431f0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Percentages\n",
    "percent_training = 0.5\n",
    "percent_test = 0.25\n",
    "percent_validation = 1 - percent_training - percent_test"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1ae1d94ffca11529"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Ntr = int(Np * percent_training)  # Number of training points\n",
    "Nte = int(Np * percent_test)  # Number of test points\n",
    "Nva = Np - Ntr - Nte\n",
    "\n",
    "X_tr = Xsh[:Ntr]\n",
    "\n",
    "mm = X_tr.mean()\n",
    "ss = X_tr.std()\n",
    "my = mm['total_UPDRS']\n",
    "sy = ss['total_UPDRS']\n",
    "mm_vals = mm.values\n",
    "ss_vals = ss.values"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c86ef7ebc1626af1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Xsh_norm = (Xsh - mm_vals) / ss_vals  # normalization of all parameters\n",
    "ysh_norm = Xsh_norm['total_UPDRS']  # total_UPDRS will be the regressand\n",
    "Xsh_norm = Xsh_norm[['motor_UPDRS', 'age', 'PPE']]  # keeping only these three regressors\n",
    "# Xsh_norm = Xsh_norm.drop(['total_UPDRS', 'subject#', 'test_time'], axis=1)  # removing the regressand and other useless\n",
    "# or known correlated features\n",
    "\n",
    "X_tr_norm = Xsh_norm[:Ntr].values\n",
    "X_va_norm = Xsh_norm[Ntr:Ntr + Nva].values\n",
    "X_te_norm = Xsh_norm[-Nte:].values\n",
    "y_tr_norm = ysh_norm[:Ntr].values\n",
    "y_va_norm = ysh_norm[Ntr:Ntr + Nva].values\n",
    "y_te_norm = ysh_norm[-Nte:].values"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "966f6ac10ac17cef"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Useful functions\n",
    "def eucl_distance(v1, v2):\n",
    "    assert len(v1) == len(v2)\n",
    "    v_diff = v1 - v2\n",
    "    return pow(v_diff.T @ v_diff, 0.5)\n",
    "\n",
    "\n",
    "def e_MSE(y, y_hat):\n",
    "    assert len(y) == len(y_hat)\n",
    "    Ndataset = len(y)\n",
    "    return sum((y[i] - y_hat[i]) ** 2 for i in range(Ndataset)) / Ndataset\n",
    "\n",
    "\n",
    "def GPR(X_tr, y_tr, X_te, y_te, r2, s2, N):\n",
    "    Ntr = len(y_tr)\n",
    "    Nte = len(y_te)\n",
    "    y_hat = np.empty(Nte)\n",
    "    variance = 0\n",
    "    for row in range(Nte):\n",
    "        x = X_te[row]\n",
    "        distances = [eucl_distance(x, X_tr[i]) for i in range(Ntr)]\n",
    "        i_order = np.argsort(distances)\n",
    "        closer_X = np.array([X_tr[i] for i in i_order[:N - 1]])\n",
    "        closer_y = np.array([y_tr[i] for i in i_order[:N - 1]])\n",
    "        Xr = np.concatenate((closer_X, [x]), axis=0)\n",
    "        Rn = np.empty(shape=(N, N))\n",
    "        for n in range(N):\n",
    "            for k in range(N):\n",
    "                Rn[n, k] = t * np.exp(- (np.linalg.norm(Xr[n] - Xr[k]) ** 2) / (2 * r2))\n",
    "                if n == k:\n",
    "                    Rn[n, k] = Rn[n, k] + s2 ** 2\n",
    "        k = Rn[-1, :N - 1]\n",
    "        d = Rn[-1, -1]\n",
    "        Rn_sub_inv = np.linalg.inv(Rn[:N - 1, :N - 1])\n",
    "        y_hat[row] = k.T @ Rn_sub_inv @ closer_y\n",
    "        variance = d - k.T @ Rn_sub_inv @ k\n",
    "    return {'y_hat': y_hat, 'variance': variance}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "37a4c1312ab173d3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Solver control plane\n",
    "r2 = 100\n",
    "t = 1\n",
    "s2 = 0.001\n",
    "N = 10"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "10bad3fea89b3625"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_hat_norm = np.empty(Nva)\n",
    "for row in range(Nva):\n",
    "    x = X_va_norm[row]\n",
    "    distances = [eucl_distance(x, X_tr_norm[i]) for i in range(Ntr)]\n",
    "    i_order = np.argsort(distances)\n",
    "    closer_X = np.array([X_tr_norm[i] for i in i_order[:N - 1]])\n",
    "    closer_y = np.array([y_tr_norm[i] for i in i_order[:N - 1]])\n",
    "    Xr = np.concatenate((closer_X, [x]), axis=0)\n",
    "    Rn = np.empty(shape=(N, N))\n",
    "    for n in range(N):\n",
    "        for k in range(N):\n",
    "            Rn[n, k] = t * np.exp(- (np.linalg.norm(Xr[n] - Xr[k]) ** 2) / (2 * r2))\n",
    "            if n == k:\n",
    "                Rn[n, k] = Rn[n, k] + s2 ** 2\n",
    "    k = Rn[-1, :N - 1]\n",
    "    d = Rn[-1, -1]\n",
    "    Rn_sub_inv = np.linalg.inv(Rn[:N - 1, :N - 1])\n",
    "    y_hat_norm[row] = k.T @ Rn_sub_inv @ closer_y\n",
    "    variance = d - k.T @ Rn_sub_inv @ k"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c1ee1a2a0e1fbb08"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_hat = y_hat_norm * sy + my\n",
    "y_va = y_va_norm * sy + my\n",
    "plt.figure()\n",
    "plt.scatter(y_va, y_hat)\n",
    "v = plt.axis()\n",
    "plt.plot([v[0], v[1]], [v[0], v[1]], 'r', linewidth=2)\n",
    "plt.xlabel(r'$y$')\n",
    "plt.ylabel(r'$\\^y$')\n",
    "plt.title('$\\^y$ versus $y$, with $r_0^2$ and $\\\\sigma_{\\\\nu 0}^2$')\n",
    "plt.grid()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f0071422fd3e78db"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Grid search section\n",
    "r2_best = r2\n",
    "s2_best = s2\n",
    "N_best = N"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1f452d4374a2e7e4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Grid search for r2\n",
    "Nr2 = 100\n",
    "r2_range = np.linspace(10, 1000, Nr2)\n",
    "errors_r2 = np.empty(Nr2)\n",
    "y_hat_norm_r2 = np.empty(Nva)\n",
    "for i in range(Nr2):\n",
    "    r2 = r2_range[i]\n",
    "    for row in range(Nva):\n",
    "        x = X_va_norm[row]\n",
    "        distances = [eucl_distance(x, X_tr_norm[i]) for i in range(Ntr)]\n",
    "        i_order = np.argsort(distances)\n",
    "        closer_X = np.array([X_tr_norm[i] for i in i_order[:N_best - 1]])\n",
    "        closer_y = np.array([y_tr_norm[i] for i in i_order[:N_best - 1]])\n",
    "        Xr = np.concatenate((closer_X, [x]), axis=0)\n",
    "        Rn = np.empty(shape=(N_best, N_best))\n",
    "        for n in range(N_best):\n",
    "            for k in range(N_best):\n",
    "                Rn[n, k] = t * np.exp(- (np.linalg.norm(Xr[n] - Xr[k]) ** 2) / (2 * r2))\n",
    "                if n == k:\n",
    "                    Rn[n, k] = Rn[n, k] + s2_best ** 2\n",
    "        k = Rn[-1, :N_best - 1]\n",
    "        d = Rn[-1, -1]\n",
    "        Rn_sub_inv = np.linalg.inv(Rn[:N_best - 1, :N_best - 1])\n",
    "        y_hat_norm_r2[row] = k.T @ Rn_sub_inv @ closer_y\n",
    "        variance = d - k.T @ Rn_sub_inv @ k\n",
    "    errors_r2[i] = e_MSE(y_va_norm, y_hat_norm_r2)\n",
    "r2_best = r2_range[np.argmin(errors_r2)]\n",
    "print(f'Best r2 found (e_MSE = {min(errors_r2)}): {r2_best}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c11debbbf68c958"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Grid search for s2\n",
    "Ns2 = 100\n",
    "s2_range = np.linspace(0.0001, 0.01, Ns2)\n",
    "errors_s2 = np.empty(Ns2)\n",
    "y_hat_norm_s2 = np.empty(Nva)\n",
    "for i in range(Ns2):\n",
    "    s2 = s2_range[i]\n",
    "    for row in range(Nva):\n",
    "        # row = 0\n",
    "        x = X_va_norm[row]\n",
    "        distances = [eucl_distance(x, X_tr_norm[i]) for i in range(Ntr)]\n",
    "        i_order = np.argsort(distances)\n",
    "        closer_X = np.array([X_tr_norm[i] for i in i_order[:N_best - 1]])\n",
    "        closer_y = np.array([y_tr_norm[i] for i in i_order[:N_best - 1]])\n",
    "        Xr = np.concatenate((closer_X, [x]), axis=0)\n",
    "        Rn = np.empty(shape=(N_best, N_best))\n",
    "        for n in range(N_best):\n",
    "            for k in range(N_best):\n",
    "                Rn[n, k] = t * np.exp(- (np.linalg.norm(Xr[n] - Xr[k]) ** 2) / (2 * r2_best))\n",
    "                if n == k:\n",
    "                    Rn[n, k] = Rn[n, k] + s2 ** 2\n",
    "        k = Rn[-1, :N_best - 1]\n",
    "        d = Rn[-1, -1]\n",
    "        Rn_sub_inv = np.linalg.inv(Rn[:N_best - 1, :N_best - 1])\n",
    "        y_hat_norm_s2[row] = k.T @ Rn_sub_inv @ closer_y\n",
    "        variance = d - k.T @ Rn_sub_inv @ k\n",
    "    errors_s2[i] = e_MSE(y_va_norm, y_hat_norm_s2)\n",
    "s2_best = s2_range[np.argmin(errors_s2)]\n",
    "print(f'Best s2 found (e_MSE = {min(errors_s2)}): {s2_best}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9e2c488409219130"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Result with best r2 and s2\n",
    "y_hat_norm_r2s2 = np.empty(Nva)\n",
    "for row in range(Nva):\n",
    "    x = X_va_norm[row]\n",
    "    distances = [eucl_distance(x, X_tr_norm[i]) for i in range(Ntr)]\n",
    "    i_order = np.argsort(distances)\n",
    "    closer_X = np.array([X_tr_norm[i] for i in i_order[:N_best - 1]])\n",
    "    closer_y = np.array([y_tr_norm[i] for i in i_order[:N_best - 1]])\n",
    "    Xr = np.concatenate((closer_X, [x]), axis=0)\n",
    "    Rn = np.empty(shape=(N_best, N_best))\n",
    "    for n in range(N_best):\n",
    "        for k in range(N_best):\n",
    "            Rn[n, k] = t * np.exp(- (np.linalg.norm(Xr[n] - Xr[k]) ** 2) / (2 * r2_best))\n",
    "            if n == k:\n",
    "                Rn[n, k] = Rn[n, k] + s2_best ** 2\n",
    "    k = Rn[-1, :N_best - 1]\n",
    "    d = Rn[-1, -1]\n",
    "    Rn_sub_inv = np.linalg.inv(Rn[:N_best - 1, :N_best - 1])\n",
    "    y_hat_norm_r2s2[row] = k.T @ Rn_sub_inv @ closer_y\n",
    "    variance = d - k.T @ Rn_sub_inv @ k"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "70bcb57f91ebc75e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_hat = y_hat_norm_r2s2 * sy + my\n",
    "y_va = y_va_norm * sy + my\n",
    "plt.figure()\n",
    "plt.scatter(y_va, y_hat)\n",
    "v = plt.axis()\n",
    "plt.plot([v[0], v[1]], [v[0], v[1]], 'r', linewidth=2)\n",
    "plt.xlabel(r'$y$')\n",
    "plt.ylabel(r'$\\^y$')\n",
    "plt.title('$\\^y$ versus $y$, with $r_{best}^2$ and $\\\\sigma_{\\\\nu best}^2$')\n",
    "plt.grid()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "11e32b6c5e3eb0a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Grid search for N\n",
    "N_range = [2, 50]\n",
    "N_values = np.arange(N_range[0], N_range[1], 1, dtype=int)\n",
    "errors_N = np.empty(len(N_values))\n",
    "y_hat_norm_N = np.empty(Nva)\n",
    "for i in range(len(N_values)):\n",
    "    N = N_values[i]\n",
    "    for row in range(Nva):\n",
    "        x = X_va_norm[row]\n",
    "        distances = [eucl_distance(x, X_tr_norm[i]) for i in range(Ntr)]\n",
    "        i_order = np.argsort(distances)\n",
    "        closer_X = np.array([X_tr_norm[i] for i in i_order[:N - 1]])\n",
    "        closer_y = np.array([y_tr_norm[i] for i in i_order[:N - 1]])\n",
    "        Xr = np.concatenate((closer_X, [x]), axis=0)\n",
    "        Rn = np.empty(shape=(N, N))\n",
    "        for n in range(N):\n",
    "            for k in range(N):\n",
    "                Rn[n, k] = t * np.exp(- (np.linalg.norm(Xr[n] - Xr[k]) ** 2) / (2 * r2_best))\n",
    "                if n == k:\n",
    "                    Rn[n, k] = Rn[n, k] + s2_best ** 2\n",
    "        k = Rn[-1, :N - 1]\n",
    "        d = Rn[-1, -1]\n",
    "        Rn_sub_inv = np.linalg.inv(Rn[:N - 1, :N - 1])\n",
    "        y_hat_norm_N[row] = k.T @ Rn_sub_inv @ closer_y\n",
    "        variance = d - k.T @ Rn_sub_inv @ k\n",
    "    errors_N[i] = e_MSE(y_va_norm, y_hat_norm_N)\n",
    "N_best = N_values[np.argmin(errors_N)]\n",
    "print(f'Best N found (e_MSE = {min(errors_N)}): {N_best}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b4f978ab7c72ba90"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Result with best r2, s2 and N\n",
    "y_hat_norm_best = np.empty(Nva)\n",
    "for row in range(Nva):\n",
    "    x = X_va_norm[row]\n",
    "    distances = [eucl_distance(x, X_tr_norm[i]) for i in range(Ntr)]\n",
    "    i_order = np.argsort(distances)\n",
    "    closer_X = np.array([X_tr_norm[i] for i in i_order[:N_best - 1]])\n",
    "    closer_y = np.array([y_tr_norm[i] for i in i_order[:N_best - 1]])\n",
    "    Xr = np.concatenate((closer_X, [x]), axis=0)\n",
    "    Rn = np.empty(shape=(N_best, N_best))\n",
    "    for n in range(N_best):\n",
    "        for k in range(N_best):\n",
    "            Rn[n, k] = t * np.exp(- (np.linalg.norm(Xr[n] - Xr[k]) ** 2) / (2 * r2_best))\n",
    "            if n == k:\n",
    "                Rn[n, k] = Rn[n, k] + s2_best ** 2\n",
    "    k = Rn[-1, :N_best - 1]\n",
    "    d = Rn[-1, -1]\n",
    "    Rn_sub_inv = np.linalg.inv(Rn[:N_best - 1, :N_best - 1])\n",
    "    y_hat_norm_best[row] = k.T @ Rn_sub_inv @ closer_y\n",
    "    variance = d - k.T @ Rn_sub_inv @ k\n",
    "y_hat_norm_best = GPR\n",
    "print(f'e_MSE: {e_MSE(y_hat_norm_best, y_va_norm)}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6df46e2adcc2ac01"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_hat = y_hat_norm_best * sy + my\n",
    "y_va = y_va_norm * sy + my\n",
    "plt.figure()\n",
    "plt.scatter(y_va, y_hat)\n",
    "v = plt.axis()\n",
    "plt.plot([v[0], v[1]], [v[0], v[1]], 'r', linewidth=2)\n",
    "plt.xlabel(r'$y$')\n",
    "plt.ylabel(r'$\\^y$')\n",
    "plt.title('$\\^y$ versus $y$, with $r_{best}^2$ and $\\\\sigma_{\\\\nu best}^2$')\n",
    "plt.grid()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4cc7cbc1d61f7171"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Test section"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "66262adf423eca58"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f'r2 = {r2_best}')\n",
    "print(f's2 = {s2_best}')\n",
    "print(f'N = {N_best}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e00df13644d6d8fb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "afe87ad24233ced3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
